---
title: "ST558 - Final Project: Modeling"
authors: Laraib Azmat
date: July 20, 2024
format: html
---
## Introduction: 

  > The base data set for this workthrough is a binary data set of survey responses to a CDC behavioral and chronic disease surveillance study done for diabetes. I have chosen `mental health`, `healthcare`, `ability/inability to see a physicians due to the cost of the visit` and `difficulty walking` as my variables. The response variable is the `presence of prediabetes or diabetes`. Here, I will be modeling using log loss. Log loss is the negative of log of likelihood, a function denoting the likelihood a model believes the real observed values could occur. Accuracy can only be applied to classification tasks and while easier to interpret, higher number means higher accuracy, its limitations mean that it cannot be applied to regression tasks. Log loss is best used for binary classifications because of the connection between the likelihood function and if the response variable is encoded as 0 or 1. 

## Initial Library Read-in:
```{r, warning = FALSE, message = FALSE}
library(readr)
library(readxl)
library(dplyr)
library(tidyverse)
library(ggplot2)
library(caret)
library(randomForest)
library(Metrics)
library(ranger)
```

## Data:
```{r}
#reading in the csv 
diabetes_model <- read_csv("./data/diabetes_data.csv")
```

```{r}
diabetes_model <- diabetes_model |>
  mutate(across(where(is_character), as_factor))
```

```{r}
#setting seed for reproducibility
set.seed(123)

#setting up to split the data into two for later use as training and testing 
train <- sample(1:nrow(diabetes_model), size = nrow(diabetes_model)*0.7)
test <- setdiff(1:nrow(diabetes_model), train)

#subsetting the data set
diabetes_train <- diabetes_model[train, ]
diabetes_test <- diabetes_model[test, ]
```

## Models: 
```{r}
#setting up training control for future models
trainctrl <- trainControl(method = "cv", 
                          number = 5, 
                          summaryFunction = mnLogLoss, 
                          classProbs = TRUE)
```

### Logistic Regression: 
  > A type of supervised statistical modeling that predicts the probability of a binary event occuring. Either it happened or it didn't. Supervised model also means that it cannot generate results. Its application to this set of data relates to both the outcome, a binary response, and the desired parameter of log loss. In logistic regression log likelihood function to determine the beta coefficient which is directly related of log loss. 
  
#### Binomial: 
```{r warning = FALSE, message = FALSE}
#setting up a seed for reproducing results
set.seed(124)

binom <- train(Diabetes_binary ~ AnyHealthcare + NoDocbcCost + Education + Income + MentHlth + PhysHlth,
                  data = diabetes_train,
                  method = "glm",
                  family = binomial,
                  preProcess = c("center", "scale"),
                  trControl = trainctrl)

#running the model
binom
```

#### Multinomial:
```{r warning = FALSE, message = FALSE}
#setting up a seed for reproducing results
set.seed(125)

multinom <- train(Diabetes_binary ~ AnyHealthcare + NoDocbcCost + Education + Income + MentHlth + PhysHlth,
              data = diabetes_train,
              method = "multinom",
              trControl = trainctrl,
              preProcess=c("center","scale"),
              trace = FALSE)

#running the model
multinom
```

#### Bayesian Generalized Linear Model:
```{r warning = FALSE, message = FALSE}
#setting up a seed for reproducing results
set.seed(126)

bayes <- train(Diabetes_binary ~ AnyHealthcare + NoDocbcCost + Education + Income + MentHlth + PhysHlth,
              data = diabetes_train,
              method = "bayesglm",
              trControl = trainctrl,
              preProcess=c("center","scale"),
              trace = FALSE)

#running the model
bayes
```

```{r}
#visualizing the three models next to each other to find the best one
rbind(c("Binomial", binom$results[c("logLoss", "logLossSD")]), #the best model by a single point 
      c("Multinomial", multinom$results[3, ][c("logLoss", "logLossSD")]),
      c("Bayesian GLM", bayes$results[c("logLoss", "logLossSD")]) #winning model by 0.000003 of a point
      )
```

### Classification Tree:
  > Classification tree are a statistical model used to predict a qualitative response that divide the possible outcomes into distinct regions that do not overlap. For every outcome that falls into a specific region a prediction is made, which is simply the mean of the response variable for the training observations in that region. As binary data is a qualitative data type, this data set is a good match for classification tree model. 

```{r warning = FALSE, message = FALSE}
#setting up a seed for reproducing results
set.seed(127)

#creating an object for the tuning parameter
cp <- expand.grid(cp = seq(0, 0.1, 0.01))

#unfortunately, the resulting tree model needed additional variables to get a better fit
classtree <- train(Diabetes_binary ~ AnyHealthcare + NoDocbcCost + Education + Income + MentHlth + PhysHlth, 
              data = diabetes_train,
              method = "rpart",
              metric = "logLoss",
              trControl = trainctrl,
              preProcess=c("center","scale"),
              tuneGrid = cp)

#running the model
classtree
```

```{r warning = FALSE, message = FALSE}
#setting up a seed for reproducing results
set.seed(128)

#altering the tuning parameter
cp2 <- expand.grid(cp = seq(0, 0.05, 0.005))

classtree2 <- train(Diabetes_binary ~ AnyHealthcare + NoDocbcCost + Education + Income + MentHlth + PhysHlth, 
              data = diabetes_train,
              method = "rpart",
              metric = "logLoss",
              trControl = trainctrl,
              preProcess=c("center","scale"),
              tuneGrid = cp2)

#running the model
classtree2
```

```{r warning = FALSE, message = FALSE}
#setting up a seed for reproducing results
set.seed(129)

#altering the tuning parameter
cp3 <- expand.grid(cp = seq(0.75, 1, 0.01))

classtree3 <- train(Diabetes_binary ~ AnyHealthcare + NoDocbcCost + Education + Income + MentHlth + PhysHlth, 
              data = diabetes_train,
              method = "rpart",
              metric = "logLoss",
              trControl = trainctrl,
              preProcess=c("center","scale"),
              tuneGrid = cp)

#running the model
classtree3
```

```{r}
#visualizing the three models next to each other to find the best level of cp
rbind(c("CP: 0-0.1, 0.01", classtree$results[1, ][c("logLoss", "logLossSD")]),
      c("CP: 0-0.05, 0.005", classtree2$results[1, ][c("logLoss", "logLossSD")]),
      c("CP: 0-1, 0.1", classtree3$results[1, ][c("logLoss", "logLossSD")])
      )
```

### Random Forest:
  > A model where when building decision trees, each time a split is made, the algorithm cannot consider the true number of predictors and instead uses a subsection of the full set. This prevents one strong predictor as being made the main one and gives other predictor variables to play an equal role. As the data in this set has a strong predictor as seen in the EDA, random forset is a good choice of a model. 
  
```{r warning = FALSE, message = FALSE}
#setting up a seed for reproducing results
set.seed(130)

#setting up mtry sequence with 11 as the number of predictors
mtry <- expand.grid(splitrule="extratrees",
                    min.node.size=100,
                    mtry = seq(1:6))

#building the model with random forest model and training it on the train data set
randtree <- train(Diabetes_binary ~ AnyHealthcare + NoDocbcCost + Education + Income + MentHlth + PhysHlth, 
                 data = diabetes_train, 
                 method = "ranger",
                 preProcess = c("center", "scale"),
                 tuneGrid = mtry,
                 ntree = 50,
                 trControl = trainctrl)

#running the model
randtree
```

```{r warning = FALSE, message = FALSE}
#setting up a seed for reproducing results
set.seed(131)

mtry2 <- expand.grid(splitrule="extratrees",
                    min.node.size=75,
                    mtry = seq(1:6))

#repeating the model
randtree2 <- train(Diabetes_binary ~ AnyHealthcare + NoDocbcCost + Education + Income + MentHlth + PhysHlth, 
                 data = diabetes_train, 
                 method = "ranger",
                 preProcess = c("center", "scale"),
                 tuneGrid = mtry2,
                 ntree = 50,
                 trControl = trainctrl)

#running the model
randtree2 
```

```{r warning = FALSE, message = FALSE}
#setting up a seed for reproducing results
set.seed(132)

#altering mtry
mtry3 <- expand.grid(splitrule="extratrees",
                    min.node.size=50,
                    mtry = seq(1:6))
#repeating the model
randtree3 <- train(Diabetes_binary ~ AnyHealthcare + NoDocbcCost + Education + Income + MentHlth + PhysHlth, 
                 data = diabetes_train, 
                 method = "ranger",
                 preProcess = c("center", "scale"),
                 tuneGrid = mtry3,
                 ntree = 50,
                 trControl = trainctrl)

#running the model
randtree3 
```

```{r}
#visualizing the three models next to each other to find the best level of mtry and n-trees
rbind(c("mtry: 1-6, nodes: 100", randtree$results[5, ][c("logLoss", "logLossSD")]),
      c("mtry: 1-6, nodes: 75", randtree2$results[5, ][c("logLoss", "logLossSD")]),
      c("mtry: 1-6, nodes: 50", randtree3$results[5, ][c("logLoss", "logLossSD")])
      )
```

## Final Model Selection: 
```{r}
#running the model over the test data with probability as the output and building it into a data frame for use in the log loss function
predicted1 <- data.frame(obs = diabetes_test$Diabetes_binary, #observation values taken from the test data set
                        pred = predict(bayes, diabetes_test), #the prediction function with raw values 
                        predict(binom, diabetes_test, type = "prob")) #probability prediction

#calculating log loss
glm_test <- mnLogLoss(predicted1, lev = levels(diabetes_test$Diabetes_binary))
```

```{r}
#repeating with classification tree model 
predicted2 <- data.frame(obs = diabetes_test$Diabetes_binary,
                        pred = predict(classtree, diabetes_test),
                        predict(classtree, diabetes_test, type = "prob"))

#calculating log loss
ct_test <- mnLogLoss(predicted2, lev = levels(diabetes_test$Diabetes_binary))
```

```{r}
#repeating with random forest
predicted3 <- data.frame(obs = diabetes_test$Diabetes_binary,
                        pred = predict(randtree, diabetes_test),
                        predict(randtree, diabetes_test, type = "prob"))

#calculating log loss
rf_test <- mnLogLoss(predicted3, lev = levels(diabetes_test$Diabetes_binary))
```

## Winning Model: 
```{r}
rbind(c("Bayes", glm_test), #the best model by a single point 
      c("Classification Tree", ct_test),
      c("Random Forest", rf_test))
```

  > The winning model in my opinion is the random forest as it showed the lowest log loss in the training models but also the lowest when using the test set. 
